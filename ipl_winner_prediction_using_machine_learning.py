# -*- coding: utf-8 -*-
"""IPL Winner Prediction Using Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iFaNcCfl4Zpv_B6yCdZSASHdJf3lAd0i
"""

import pandas as pd

df_matches=pd.read_csv('/content/drive/MyDrive/cricket dataset/ipl_2008_2022/matches_updated_mens_ipl.csv')

df_matches.head()

"""Grouping Batsmen by Matches"""



"""**Data Preprocessing**"""

df_matches.columns

df=df_matches[['team1','team2','season','venue','toss_winner','toss_decision','winner_runs','winner_wickets','winner']]
df

df.isnull().sum()

columns = ['winner']
df[columns] = df[columns].fillna('Draw')

columns_to_fill = ['winner_runs','winner_wickets']

# Fill null values with zero in specific columns
df[columns_to_fill] = df[columns_to_fill].fillna(0)

df.isnull().sum()

df=df.replace(['Delhi Daredevils','Kings XI Punjab','Rising Pune Supergiant'],['Delhi Capitals','Punjab Kings','Rising Pune Supergiants'])
df.replace(['Mumbai Indians','Kolkata Knight Riders','Royal Challengers Bangalore','Deccan Chargers','Chennai Super Kings',
                 'Rajasthan Royals','Delhi Capitals','Gujarat Lions','Punjab Kings',
                 'Sunrisers Hyderabad','Rising Pune Supergiants','Kochi Tuskers Kerala','Pune Warriors','Lucknow Super Giants','Gujarat Titans']
                ,['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW','LSG','GT'],inplace=True)

encode = {
    'team1': {'MI': 0, 'KKR': 1, 'RCB': 2, 'DC': 3, 'CSK': 4, 'RR': 5, 'DD': 6, 'GL': 7, 'KXIP': 8, 'SRH': 9, 'RPS': 10, 'KTK': 11, 'PW': 12, 'LSG': 13, 'GT': 14},
    'team2': {'MI': 0, 'KKR': 1, 'RCB': 2, 'DC': 3, 'CSK': 4, 'RR': 5, 'DD': 6, 'GL': 7, 'KXIP': 8, 'SRH': 9, 'RPS': 10, 'KTK': 11, 'PW': 12, 'LSG': 13, 'GT': 14},
    'toss_winner': {'MI': 0, 'KKR': 1, 'RCB': 2, 'DC': 3, 'CSK': 4, 'RR': 5, 'DD': 6, 'GL': 7, 'KXIP': 8, 'SRH': 9, 'RPS': 10, 'KTK': 11, 'PW': 12, 'LSG': 13, 'GT': 14},
    'winner': {'MI': 0, 'KKR': 1, 'RCB': 2, 'DC': 3, 'CSK': 4, 'RR': 5, 'DD': 6, 'GL': 7, 'KXIP': 8, 'SRH': 9, 'RPS': 10, 'KTK': 11, 'PW': 12, 'Draw': 13, 'LSG': 13, 'GT': 14}
}

df.replace(encode, inplace=True)

df.dtypes

df.head()

df['team1'].value_counts()

from sklearn.preprocessing import LabelEncoder
var_mod = ['season','venue','toss_decision']
le = LabelEncoder()
for i in var_mod:
    df[i] = le.fit_transform(df[i])
df.dtypes

df.head()

df.columns

x=df[['team1', 'team2', 'season', 'venue', 'toss_winner', 'toss_decision',
       'winner_runs', 'winner_wickets']]
y=df['winner']

"""### **Train Test Split**"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7,shuffle=True)

"""### **Apply Machine Learning Models**

DecisionTreeClassifier
"""

from sklearn.tree import DecisionTreeClassifier

dt=DecisionTreeClassifier()
dt_model=dt.fit(x_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
dt_pred=dt_model.predict(x_test)
dt_cm = confusion_matrix(y_test,dt_pred)
dt_cm

dt_train=dt_model.predict(x_train)
acc=accuracy_score(y_train,dt_train)
acc

dt_acc=accuracy_score(y_test,dt_pred)
dt_acc

"""RandomForest Classifier"""

from sklearn.ensemble import RandomForestClassifier
rf= RandomForestClassifier(n_estimators= 10, criterion="entropy")

rf_model=rf.fit(x_train,y_train)
rf_pred=rf_model.predict(x_test)

rf_cm=confusion_matrix(y_test,rf_pred)
rf_cm

rf_acc=accuracy_score(y_test,rf_pred)
rf_acc

"""Gaussian NB"""

from sklearn.naive_bayes import GaussianNB
nb=GaussianNB()
nb_model=nb.fit(x_train,y_train)
nb_pred=nb_model.predict(x_test)

nb_cm=confusion_matrix(y_test,nb_pred)
nb_cm

nb_acc=accuracy_score(y_test,nb_pred)
nb_acc

"""XGBClassifier"""

from xgboost import XGBClassifier
xg=XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1)
xg_model=xg.fit(x_train,y_train)

xg_pred=xg_model.predict(x_test)

xg_cm=confusion_matrix(y_test,xg_pred)
xg_cm

xg_acc=accuracy_score(y_test,xg_pred)
xg_acc

"""Grid Search - Decicion Tree"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

grid_search = GridSearchCV(dt_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(x_train, y_train)
print("Best Hyperparameters:", grid_search.best_params_)
best_dt_model = grid_search.best_estimator_

gs_dt_pred = best_dt_model.predict(x_test)

gs_dt_acc=accuracy_score(y_test,gs_dt_pred)
gs_dt_acc

